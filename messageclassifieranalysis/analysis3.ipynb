{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import loaddata\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import sklearn.feature_extraction.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messages = loaddata.load_message()\n",
    "content = np.array([m[0] for m in messages])\n",
    "target = np.array([m[1] for m in messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "DEBUG:jieba:Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.732 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.732 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23734, 4869)\n"
     ]
    }
   ],
   "source": [
    "class MessageCountVectorizer(sklearn.feature_extraction.text.CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        def analyzer(doc):\n",
    "            words = pseg.cut(doc)\n",
    "            new_doc = ''.join(w.word for w in words if w.flag != 'x')\n",
    "            words = jieba.cut(new_doc)\n",
    "            return words\n",
    "        return analyzer\n",
    "\n",
    "vec_count = MessageCountVectorizer(min_df=10,max_df=0.8)\n",
    "data_count = vec_count.fit_transform(content)\n",
    "vec_count.get_feature_names()\n",
    "print(data_count.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.95761355018117467, SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False), {'C': 0.1, 'kernel': 'linear'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "def find_best_svm(data, target, cv):\n",
    "    clf = SVC()\n",
    "    C = [0.1, 0.5, 0.75, 1, 2, 3, 5, 10, 20]\n",
    "    kernel = ['linear']#, 'poly', 'rbf']\n",
    "    param_grid = [{'C': C, 'kernel':kernel}]\n",
    "    grid_search = GridSearchCV(clf, param_grid=param_grid, cv=cv)\n",
    "    grid_search.fit(data, target)\n",
    "    grid_search.cls_name = 'SVM'\n",
    "    return grid_search\n",
    "grid_svm = find_best_svm(data_count, target, cv=10)\n",
    "grid_svm.grid_scores_\n",
    "grid_svm.best_score_, grid_svm.best_estimator_, grid_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.956613310868\n",
      "1 0.964616680708\n",
      "2 0.962931760741\n",
      "3 0.964616680708\n",
      "4 0.969250210615\n",
      "5 0.961668070767\n",
      "6 0.952401010952\n",
      "7 0.960404380792\n",
      "8 0.960825610783\n",
      "9 0.9599831508\n",
      "|class|4|5|3|6|1|2|\n",
      "|-|\n",
      "|0|0.8906|0.9563|0.6667|0.7869|0.9896|0.9479|\n",
      "|1|0.8962|0.9682|0.7647|0.8500|0.9857|0.9585|\n",
      "|2|0.8962|0.9584|0.5789|0.7931|0.9945|0.9611|\n",
      "|3|0.8939|0.9699|0.6667|0.8060|0.9953|0.9575|\n",
      "|4|0.9096|0.9693|0.7619|0.8696|0.9953|0.9588|\n",
      "|5|0.8579|0.9679|0.6000|0.7544|0.9928|0.9540|\n",
      "|6|0.8159|0.9573|0.6429|0.7975|0.9883|0.9610|\n",
      "|7|0.8833|0.9521|0.5455|0.7302|0.9929|0.9613|\n",
      "|8|0.8981|0.9666|0.6667|0.7941|0.9917|0.9449|\n",
      "|9|0.8469|0.9548|0.6429|0.9149|0.9888|0.9615|\n",
      "|max|0.9096|0.9699|0.7647|0.9149|0.9953|0.9615|\n",
      "|min|0.8159|0.9521|0.5455|0.7302|0.9857|0.9449|\n",
      "|mean|0.8789|0.9621|0.6537|0.8097|0.9915|0.9567|\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "def get_classes_accury(data, target, test_times = 10, test_size=0.1):\n",
    "    scores = np.zeros((test_times,len(set(target))))\n",
    "    for t in range(test_times):\n",
    "        clf =SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
    "   decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
    "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "   tol=0.001, verbose=False)\n",
    "        Xtrain, Xtest, ytrain, ytest = train_test_split(data, target, test_size=test_size,\n",
    "                                                    random_state=t)\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        print(t, clf.score(Xtest, ytest))\n",
    "        pre = clf.predict(Xtest)\n",
    "        for i,c in enumerate(list(set(target))):\n",
    "            s = np.logical_and(pre==c, ytest==c).sum()/ (ytest==c).sum()\n",
    "            scores[t, i] = s\n",
    "\n",
    "    ##### 生成表格\n",
    "    print('|'+'class'+'|'+'|'.join([str(i) for i  in list(set(target))])+'|')\n",
    "    print('|'+'-'+'|')\n",
    "    for i,score in enumerate(scores):\n",
    "        print( '|'+str(i)+'|'+ '|'.join(['{:.4f}'.format(_) for _ in score])+ '|' )\n",
    "    print( '|'+'max'+ '|'+ '|'.join(['{:.4f}'.format(_) for _ in scores.max(axis=0)])+ '|' )\n",
    "    print( '|'+'min'+ '|'+ '|'.join(['{:.4f}'.format(_) for _ in scores.min(axis=0)])+ '|' )\n",
    "    print( '|'+'mean'+'|'+  '|'.join(['{:.4f}'.format(_) for _ in scores.mean(axis=0)])+ '|' )\n",
    "\n",
    "    return scores\n",
    "scores = get_classes_accury(data_count, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23734, 4869)\n"
     ]
    }
   ],
   "source": [
    "class TfidfVectorizer(sklearn.feature_extraction.text.TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        #analyzer = super(TfidfVectorizer, self).build_analyzer()\n",
    "        def analyzer(doc):\n",
    "            words = pseg.cut(doc)\n",
    "            new_doc = ''.join(w.word for w in words if w.flag != 'x')\n",
    "            words = jieba.cut(new_doc)\n",
    "            return words\n",
    "        return analyzer\n",
    "\n",
    "vec_tfidf = TfidfVectorizer(min_df=10,max_df=0.8)\n",
    "data_tfidf = vec_tfidf.fit_transform(content)\n",
    "print(data_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mean: 0.92146, std: 0.02057, params: {'C': 0.1, 'kernel': 'linear'}, mean: 0.95348, std: 0.01235, params: {'C': 0.5, 'kernel': 'linear'}, mean: 0.95698, std: 0.01227, params: {'C': 0.75, 'kernel': 'linear'}, mean: 0.95816, std: 0.01185, params: {'C': 1, 'kernel': 'linear'}, mean: 0.95943, std: 0.01222, params: {'C': 2, 'kernel': 'linear'}, mean: 0.95947, std: 0.01135, params: {'C': 3, 'kernel': 'linear'}, mean: 0.95892, std: 0.01137, params: {'C': 4, 'kernel': 'linear'}, mean: 0.95770, std: 0.01176, params: {'C': 5, 'kernel': 'linear'}, mean: 0.95546, std: 0.01171, params: {'C': 10, 'kernel': 'linear'}, mean: 0.95365, std: 0.01191, params: {'C': 30, 'kernel': 'linear'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.95946743069014917, SVC(C=3, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False), {'C': 3, 'kernel': 'linear'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_SVM(data, target):\n",
    "    from sklearn.grid_search import GridSearchCV\n",
    "    from sklearn.svm import SVC\n",
    "    clf = SVC()\n",
    "\n",
    "    C = [0.1, 0.5, 0.75, 1, 2, 3, 4, 5, 10, 30]\n",
    "    kernel = ['linear'] # 'poly',\n",
    "    param_grid = [{'C': C, 'kernel':kernel}]\n",
    "    grid_search = GridSearchCV(clf, param_grid=param_grid, cv=10)\n",
    "    grid_search.fit(data, target)\n",
    "\n",
    "    return grid_search\n",
    "grid_search = test_SVM(data_tfidf, target)\n",
    "print(grid_search.grid_scores_)\n",
    "grid_search.best_score_, grid_search.best_estimator_, grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
