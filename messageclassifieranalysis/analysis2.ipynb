{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import loaddata\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import sklearn.feature_extraction.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messages = loaddata.load_message()\n",
    "content = np.array([m[0] for m in messages])\n",
    "target = np.array([m[1] for m in messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "DEBUG:jieba:Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.732 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.732 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23734, 8895)\n"
     ]
    }
   ],
   "source": [
    "class MessageCountVectorizer(sklearn.feature_extraction.text.CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        def analyzer(doc):\n",
    "            words = pseg.cut(doc)\n",
    "            new_doc = ''.join(w.word for w in words if w.flag != 'x')\n",
    "            words = jieba.cut(new_doc)\n",
    "            return words\n",
    "        return analyzer\n",
    "\n",
    "vec_count = MessageCountVectorizer(min_df=5,max_df=0.8)\n",
    "data_count = vec_count.fit_transform(content)\n",
    "vec_count.get_feature_names()\n",
    "print(data_count.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.96081570742394873, SVC(C=0.5, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False), {'C': 0.5, 'kernel': 'linear'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "def find_best_svm(data, target, cv):\n",
    "    clf = SVC()\n",
    "    C = [0.1, 0.5, 0.75, 1, 2, 3, 5, 10, 20]\n",
    "    kernel = ['linear']#, 'poly', 'rbf']\n",
    "    param_grid = [{'C': C, 'kernel':kernel}]\n",
    "    grid_search = GridSearchCV(clf, param_grid=param_grid, cv=cv)\n",
    "    grid_search.fit(data, target)\n",
    "    grid_search.cls_name = 'SVM'\n",
    "    return grid_search\n",
    "grid_svm = find_best_svm(data_count, target, cv=10)\n",
    "grid_svm.grid_scores_\n",
    "grid_svm.best_score_, grid_svm.best_estimator_, grid_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.958719460826\n",
      "1 0.965037910699\n",
      "2 0.963352990733\n",
      "3 0.966722830666\n",
      "4 0.973041280539\n",
      "5 0.96251053075\n",
      "6 0.955349620893\n",
      "7 0.965037910699\n",
      "8 0.96251053075\n",
      "9 0.961668070767\n",
      "|class|6|3|5|4|2|1|\n",
      "|-|\n",
      "|0|0.8361|0.7083|0.9506|0.9167|0.9440|0.9905|\n",
      "|1|0.8833|0.7647|0.9588|0.9071|0.9629|0.9857|\n",
      "|2|0.8621|0.5789|0.9471|0.9245|0.9546|0.9945|\n",
      "|3|0.9104|0.7500|0.9679|0.8939|0.9595|0.9916|\n",
      "|4|0.9275|0.8095|0.9655|0.9149|0.9725|0.9934|\n",
      "|5|0.8596|0.6000|0.9566|0.8579|0.9582|0.9928|\n",
      "|6|0.8608|0.6429|0.9536|0.8458|0.9610|0.9864|\n",
      "|7|0.7778|0.6364|0.9500|0.9167|0.9729|0.9893|\n",
      "|8|0.7941|0.7333|0.9548|0.9223|0.9592|0.9890|\n",
      "|9|0.9362|0.7143|0.9403|0.8929|0.9676|0.9869|\n",
      "|max|0.9362|0.8095|0.9679|0.9245|0.9729|0.9945|\n",
      "|min|0.7778|0.5789|0.9403|0.8458|0.9440|0.9857|\n",
      "|mean|0.8648|0.6938|0.9545|0.8993|0.9612|0.9900|\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "def get_classes_accury(data, target, test_times = 10, test_size=0.1):\n",
    "    scores = np.zeros((test_times,len(set(target))))\n",
    "    for t in range(test_times):\n",
    "        clf =SVC(C=0.5, cache_size=200, class_weight=None, coef0=0.0,\n",
    "   decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
    "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "   tol=0.001, verbose=False)\n",
    "        Xtrain, Xtest, ytrain, ytest = train_test_split(data, target, test_size=test_size,\n",
    "                                                    random_state=t)\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        print(t, clf.score(Xtest, ytest))\n",
    "        pre = clf.predict(Xtest)\n",
    "        for i,c in enumerate(list(set(target))):\n",
    "            s = np.logical_and(pre==c, ytest==c).sum()/ (ytest==c).sum()\n",
    "            scores[t, i] = s\n",
    "\n",
    "    ##### 生成表格\n",
    "    print('|'+'class'+'|'+'|'.join([str(i) for i  in list(set(target))])+'|')\n",
    "    print('|'+'-'+'|')\n",
    "    for i,score in enumerate(scores):\n",
    "        print( '|'+str(i)+'|'+ '|'.join(['{:.4f}'.format(_) for _ in score])+ '|' )\n",
    "    print( '|'+'max'+ '|'+ '|'.join(['{:.4f}'.format(_) for _ in scores.max(axis=0)])+ '|' )\n",
    "    print( '|'+'min'+ '|'+ '|'.join(['{:.4f}'.format(_) for _ in scores.min(axis=0)])+ '|' )\n",
    "    print( '|'+'mean'+'|'+  '|'.join(['{:.4f}'.format(_) for _ in scores.mean(axis=0)])+ '|' )\n",
    "\n",
    "    return scores\n",
    "scores = get_classes_accury(data_count, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23734, 8895)\n"
     ]
    }
   ],
   "source": [
    "class TfidfVectorizer(sklearn.feature_extraction.text.TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        #analyzer = super(TfidfVectorizer, self).build_analyzer()\n",
    "        def analyzer(doc):\n",
    "            words = pseg.cut(doc)\n",
    "            new_doc = ''.join(w.word for w in words if w.flag != 'x')\n",
    "            words = jieba.cut(new_doc)\n",
    "            return words\n",
    "        return analyzer\n",
    "\n",
    "vec_tfidf = TfidfVectorizer(min_df=5,max_df=0.8)\n",
    "data_tfidf = vec_tfidf.fit_transform(content)\n",
    "print(data_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mean: 0.91860, std: 0.02108, params: {'C': 0.1, 'kernel': 'linear'}, mean: 0.95450, std: 0.01219, params: {'C': 0.5, 'kernel': 'linear'}, mean: 0.95770, std: 0.01158, params: {'C': 0.75, 'kernel': 'linear'}, mean: 0.95926, std: 0.01140, params: {'C': 1, 'kernel': 'linear'}, mean: 0.96229, std: 0.01092, params: {'C': 2, 'kernel': 'linear'}, mean: 0.96208, std: 0.01102, params: {'C': 3, 'kernel': 'linear'}, mean: 0.96162, std: 0.01125, params: {'C': 4, 'kernel': 'linear'}, mean: 0.96166, std: 0.01153, params: {'C': 5, 'kernel': 'linear'}, mean: 0.96027, std: 0.01113, params: {'C': 10, 'kernel': 'linear'}, mean: 0.95858, std: 0.01112, params: {'C': 30, 'kernel': 'linear'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.96229038510154208, SVC(C=2, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False), {'C': 2, 'kernel': 'linear'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_SVM(data, target):\n",
    "    from sklearn.grid_search import GridSearchCV\n",
    "    from sklearn.svm import SVC\n",
    "    clf = SVC()\n",
    "\n",
    "    C = [0.1, 0.5, 0.75, 1, 2, 3, 4, 5, 10, 30]\n",
    "    kernel = ['linear'] # 'poly',\n",
    "    param_grid = [{'C': C, 'kernel':kernel}]\n",
    "    grid_search = GridSearchCV(clf, param_grid=param_grid, cv=10)\n",
    "    grid_search.fit(data, target)\n",
    "\n",
    "    return grid_search\n",
    "grid_search = test_SVM(data_tfidf, target)\n",
    "print(grid_search.grid_scores_)\n",
    "grid_search.best_score_, grid_search.best_estimator_, grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
