{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import loaddata\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import sklearn.feature_extraction.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messages = loaddata.load_message()\n",
    "content = np.array([m[0] for m in messages])\n",
    "target = np.array([m[1] for m in messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "DEBUG:jieba:Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.747 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.747 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "DEBUG:jieba:Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23734, 1179)\n"
     ]
    }
   ],
   "source": [
    "class MessageCountVectorizer(sklearn.feature_extraction.text.CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        def analyzer(doc):\n",
    "            words = pseg.cut(doc)\n",
    "            new_doc = ''.join(w.word for w in words if w.flag != 'x')\n",
    "            words = jieba.cut(new_doc)\n",
    "            return words\n",
    "        return analyzer\n",
    "\n",
    "vec_count = MessageCountVectorizer(min_df=50,max_df=0.8)\n",
    "data_count = vec_count.fit_transform(content)\n",
    "vec_count.get_feature_names()\n",
    "print(data_count.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.94282463975731023, SVC(C=0.5, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False), {'C': 0.5, 'kernel': 'linear'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "def find_best_svm(data, target, cv):\n",
    "    clf = SVC()\n",
    "    C = [0.1, 0.5, 0.75, 1, 2, 3, 5, 10, 20]\n",
    "    kernel = ['linear']#, 'poly', 'rbf']\n",
    "    param_grid = [{'C': C, 'kernel':kernel}]\n",
    "    grid_search = GridSearchCV(clf, param_grid=param_grid, cv=cv)\n",
    "    grid_search.fit(data, target)\n",
    "    grid_search.cls_name = 'SVM'\n",
    "    return grid_search\n",
    "grid_svm = find_best_svm(data_count, target, cv=10)\n",
    "grid_svm.grid_scores_\n",
    "grid_svm.best_score_, grid_svm.best_estimator_, grid_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.94650379107\n",
      "1 0.943133951137\n",
      "2 0.946082561078\n",
      "3 0.954928390901\n",
      "4 0.960404380792\n",
      "5 0.946925021061\n",
      "6 0.93850042123\n",
      "7 0.950294860994\n",
      "8 0.949452401011\n",
      "9 0.940185341196\n",
      "|class|1|3|6|5|2|4|\n",
      "|-|\n",
      "|0|0.9848|0.6667|0.7705|0.9373|0.9498|0.8438|\n",
      "|1|0.9777|0.5882|0.8333|0.9251|0.9476|0.8415|\n",
      "|2|0.9909|0.5263|0.7931|0.9112|0.9460|0.8821|\n",
      "|3|0.9860|0.7917|0.8060|0.9499|0.9459|0.8939|\n",
      "|4|0.9925|0.8095|0.8116|0.9483|0.9510|0.9096|\n",
      "|5|0.9866|0.7000|0.7018|0.9358|0.9351|0.8579|\n",
      "|6|0.9825|0.5714|0.7848|0.9481|0.9415|0.7662|\n",
      "|7|0.9831|0.5455|0.7302|0.9417|0.9574|0.8500|\n",
      "|8|0.9853|0.7333|0.7353|0.9489|0.9449|0.8592|\n",
      "|9|0.9813|0.7857|0.7872|0.9186|0.9474|0.8061|\n",
      "|max|0.9925|0.8095|0.8333|0.9499|0.9574|0.9096|\n",
      "|min|0.9777|0.5263|0.7018|0.9112|0.9351|0.7662|\n",
      "|mean|0.9851|0.6718|0.7754|0.9365|0.9467|0.8510|\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "def get_classes_accury(data, target, test_times = 10, test_size=0.1):\n",
    "    scores = np.zeros((test_times,len(set(target))))\n",
    "    for t in range(test_times):\n",
    "        clf =SVC(C=0.5, cache_size=200, class_weight=None, coef0=0.0,\n",
    "   decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
    "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "   tol=0.001, verbose=False)\n",
    "        Xtrain, Xtest, ytrain, ytest = train_test_split(data, target, test_size=test_size,\n",
    "                                                    random_state=t)\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        print(t, clf.score(Xtest, ytest))\n",
    "        pre = clf.predict(Xtest)\n",
    "        for i,c in enumerate(list(set(target))):\n",
    "            s = np.logical_and(pre==c, ytest==c).sum()/ (ytest==c).sum()\n",
    "            scores[t, i] = s\n",
    "\n",
    "    ##### 生成表格\n",
    "    print('|'+'class'+'|'+'|'.join([str(i) for i  in list(set(target))])+'|')\n",
    "    print('|'+'-'+'|')\n",
    "    for i,score in enumerate(scores):\n",
    "        print( '|'+str(i)+'|'+ '|'.join(['{:.4f}'.format(_) for _ in score])+ '|' )\n",
    "    print( '|'+'max'+ '|'+ '|'.join(['{:.4f}'.format(_) for _ in scores.max(axis=0)])+ '|' )\n",
    "    print( '|'+'min'+ '|'+ '|'.join(['{:.4f}'.format(_) for _ in scores.min(axis=0)])+ '|' )\n",
    "    print( '|'+'mean'+'|'+  '|'.join(['{:.4f}'.format(_) for _ in scores.mean(axis=0)])+ '|' )\n",
    "\n",
    "    return scores\n",
    "scores = get_classes_accury(data_count, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s ='''\n",
    "|class|3|2|6|1|4|5|\n",
    "|mean|0.6878|0.9624|0.8616|0.9923|0.9004|0.9541|\n",
    "|class|6|3|5|4|2|1|\n",
    "|mean|0.8648|0.6938|0.9545|0.8993|0.9612|0.9900|\n",
    "|class|4|5|3|6|1|2|\n",
    "|mean|0.8789|0.9621|0.6537|0.8097|0.9915|0.9567|\n",
    "|class|1|3|6|5|2|4|\n",
    "|mean|0.9851|0.6718|0.7754|0.9365|0.9467|0.8510|\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Tokenizer.cut at 0x7f1ead6175c8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.cut('尊 敬的用 户:您2009年10月份的积 分奖 品尚未领 取,请拨I259O7612按 2键领 取(48小时内有效)咨 询95105526')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['尊',\n",
       " ' ',\n",
       " '敬',\n",
       " '的',\n",
       " '用',\n",
       " ' ',\n",
       " '户',\n",
       " ':',\n",
       " '您',\n",
       " '2009',\n",
       " '年',\n",
       " '10',\n",
       " '月份',\n",
       " '的',\n",
       " '积',\n",
       " ' ',\n",
       " '分奖',\n",
       " ' ',\n",
       " '品',\n",
       " '尚未',\n",
       " '领',\n",
       " ' ',\n",
       " '取',\n",
       " ',',\n",
       " '请拨',\n",
       " 'I259O7612',\n",
       " '按',\n",
       " ' ',\n",
       " '2',\n",
       " '键领',\n",
       " ' ',\n",
       " '取',\n",
       " '(',\n",
       " '48',\n",
       " '小时',\n",
       " '内',\n",
       " '有效',\n",
       " ')',\n",
       " '咨',\n",
       " ' ',\n",
       " '询',\n",
       " '95105526']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in jieba.cut('尊 敬的用 户:您2009年10月份的积 分奖 品尚未领 取,请拨I259O7612按 2键领 取(48小时内有效)咨 询95105526')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23734, 1179)\n"
     ]
    }
   ],
   "source": [
    "class TfidfVectorizer(sklearn.feature_extraction.text.TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        #analyzer = super(TfidfVectorizer, self).build_analyzer()\n",
    "        def analyzer(doc):\n",
    "            words = pseg.cut(doc)\n",
    "            new_doc = ''.join(w.word for w in words if w.flag != 'x')\n",
    "            words = jieba.cut(new_doc)\n",
    "            return words\n",
    "        return analyzer\n",
    "\n",
    "vec_tfidf = TfidfVectorizer(min_df=50,max_df=0.8)\n",
    "data_tfidf = vec_tfidf.fit_transform(content)\n",
    "print(data_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mean: 0.92011, std: 0.01803, params: {'C': 0.1, 'kernel': 'linear'}, mean: 0.93975, std: 0.01423, params: {'C': 0.5, 'kernel': 'linear'}, mean: 0.94198, std: 0.01328, params: {'C': 0.75, 'kernel': 'linear'}, mean: 0.94278, std: 0.01305, params: {'C': 1, 'kernel': 'linear'}, mean: 0.94379, std: 0.01294, params: {'C': 2, 'kernel': 'linear'}, mean: 0.94367, std: 0.01332, params: {'C': 3, 'kernel': 'linear'}, mean: 0.94266, std: 0.01378, params: {'C': 5, 'kernel': 'linear'}, mean: 0.94084, std: 0.01359, params: {'C': 10, 'kernel': 'linear'}, mean: 0.93524, std: 0.01245, params: {'C': 30, 'kernel': 'linear'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.94379371365972864, SVC(C=2, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False), {'C': 2, 'kernel': 'linear'})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_SVM(data, target):\n",
    "    from sklearn.grid_search import GridSearchCV\n",
    "    from sklearn.svm import SVC\n",
    "    clf = SVC()\n",
    "\n",
    "    C = [0.1, 0.5, 0.75, 1, 2, 3, 5, 10, 30]\n",
    "    kernel = ['linear'] # 'poly',\n",
    "    param_grid = [{'C': C, 'kernel':kernel}]\n",
    "    grid_search = GridSearchCV(clf, param_grid=param_grid, cv=10)\n",
    "    grid_search.fit(data, target)\n",
    "\n",
    "    return grid_search\n",
    "grid_search = test_SVM(data_tfidf, target)\n",
    "print(grid_search.grid_scores_)\n",
    "grid_search.best_score_, grid_search.best_estimator_, grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
